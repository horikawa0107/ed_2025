import asyncio
from bleak import BleakScanner
import json
import gc
import pandas as pd
from datetime import datetime
from threading import Thread
from flask import jsonify
import requests
import numpy as np
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
from flask import Flask, render_template,redirect,request
import mysql.connector
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import time
import threading
import random

app = Flask(__name__)
# ğŸ”½ ã“ã“ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ã¦å¤‰æ•°ã«ã‚»ãƒƒãƒˆ

def get_db_connection():
    return mysql.connector.connect(
        host='localhost',
        user='root',
        password='password',
        database='ed_2025'
    )

# ğŸ”½ è¿½åŠ : room_infoãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰BLEã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆå­¦ç¿’ç”¨ï¼‰ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_ble_address_capacity_from_db():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT ble_address,capacity,mist_ap_address FROM room_info WHERE room_type = %s", (0,))
    result = cursor.fetchone()
    cursor.close()
    conn.close()
    if result:
        return result[0],result[1],result[2]
    else:
        raise ValueError("åŸºæº–ã®éƒ¨å±‹ã®ble_addressãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

def get_ble_address_from_db():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT ble_address,id FROM room_info")
    result = cursor.fetchall()
    cursor.close()
    conn.close()
    if result:
        return result
    else:
        raise ValueError("ä»–ã®room_idã®ble_addressãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")


OMRON_ADDRESS_FOR_ML,CAPACITY,MIST_AP_ADDRESS = get_ble_address_capacity_from_db()
# DBã‹ã‚‰BLEã‚¢ãƒ‰ãƒ¬ã‚¹ã¨room_idã‚’å–å¾—
rows = get_ble_address_from_db()
parsed_counts = {}  # â† omron_addressã”ã¨ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’ä¿æŒã™ã‚‹è¾æ›¸

# rows: [(ble_address, id), (ble_address, id), ...]
OMRON_ADDRESSES = tuple([row[0] for row in rows])
ROOM_IDS        = tuple([row[1] for row in rows])

print(f"ä½¿ç”¨ã™ã‚‹å­¦ç¿’ç”¨ã®OMRON BLEã‚¢ãƒ‰ãƒ¬ã‚¹: {OMRON_ADDRESS_FOR_ML}")
print(f"ä½¿ç”¨ã™ã‚‹åå®¹äººæ•°: {CAPACITY}")
print(f"ä½¿ç”¨ã™ã‚‹MIST AP: {MIST_AP_ADDRESS}")
print(f"ä½¿ç”¨ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹é‹ç”¨ç”¨ã®OMRON BLEã‚¢ãƒ‰ãƒ¬ã‚¹: {OMRON_ADDRESSES}")
print(f"ä½¿ç”¨ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹é‹ç”¨ç”¨ã®room_id: {ROOM_IDS}")

#ãƒ‘ã‚¹ã¯å„è‡ªã®ç’°å¢ƒã«è¨­å®šã™ã‚‹
MODEL_PATH="/Users/horikawafuka2/Documents/class_2025/ed/dev_mysql/models/comfort_model_xgb.pkl"
OMRON_MANUFACTURER_ID = 725
ERROR_LOG_FILE = "/Users/horikawafuka2/Documents/class_2025/ed/dev_mysql/errors.json"
API_URL = 'https://weather.tsukumijima.net/api/forecast/city/400040'
#------------MIST API------------
API_TOKEN = "ycQduGG1tfVDuCYRdQDbMPoO2qU66UdD8e2xmIeWSHXQ81ZZxSzHYD5w85vCcKiDbL6lWTbwT124q9EnGTlO6fay6X08KF0w"
# ORG_ID = "14e64971-8492-40c9-9b5f-c169ea5c6903"
ORG_ID = "0ec9ad75-1ae0-40b3-bbd8-63ac91775547"
# SITE_ID = "b9b7b9d1-4823-465c-9bcf-14a0659003c6"
SITE_ID="22968ecf-ae7b-4d84-8100-670bb522267b"
# AP_ID = "00000000-0000-0000-1000-5c5b353ecdc3"
AP_ID = "00000000-0000-0000-1000-5c5b353ecdd7"

#---------------------------------
UPDATE_INTERVAL = 300  # 5åˆ†ã”ã¨ã«å†å­¦ç¿’



# 2. MySQLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆå‰å‡¦ç†æ¸ˆã¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
def load_data_from_mysql():
    print("processed_sensor_data_for_mlã‹ã‚‰èª­ã¿è¾¼ã¿")
    conn = get_db_connection()
    query = """
        SELECT avg_temperature, avg_humidity, avg_light, avg_pressure, avg_sound_level, month, score_from_avg_device_count
        FROM processed_sensor_data_for_ml
        ORDER BY timestamp DESC limit 5;
    """
    df = pd.read_sql(query, conn)
    conn.close()
    return df

def get_lateset_processed_sensor_data():
    print("processed_sensor_dataã‹ã‚‰èª­ã¿è¾¼ã¿")
    conn = get_db_connection()
    query = """
        SELECT id,avg_temperature, avg_humidity, avg_light, avg_pressure, avg_sound_level, month
        FROM processed_sensor_data
        ORDER BY timestamp DESC limit 1;
    """
    df = pd.read_sql(query, conn)
    conn.close()
    return df



def train_and_save_model(load_data_func=None):
    current_time = datetime.now()

    # --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    if load_data_func is None:
        df = load_data_from_mysql()
    else:
        df = load_data_func()
    print(f"processed_sensor_data_for_ml: {df}")
    if df.empty or len(df) < 5:
        print(f"{current_time}æ™‚ç‚¹ã§ãƒ‡ãƒ¼ã‚¿ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    # --- å¿…é ˆã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ†ã‚¹ãƒˆã§ KeyError ã‚’æœŸå¾…ï¼‰ -------------------------------
    try:
        required_columns = [
            'avg_temperature',
            'avg_humidity',
            'avg_light',
            'avg_pressure',
            'avg_sound_level',
            'month',
            'score_from_avg_device_count'
        ]
        df = df[required_columns]
    except Exception as e:
        raise KeyError


    # --- ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã«åˆ†å‰² ---
    features = [
        'avg_temperature',
        'avg_humidity',
        'avg_light',
        'avg_pressure',
        'avg_sound_level',
        'month'
    ]
    X = df[features]
    y = df['score_from_avg_device_count']

    # --- å­¦ç¿’ç”¨ãƒ»ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰² ---
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # --- ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ or åˆæœŸåŒ– ---
    if os.path.exists(MODEL_PATH):
        print("æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€è¿½åŠ å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™...")
        model = XGBRegressor()
        model.load_model(MODEL_PATH)
        model.fit(X_train, y_train, xgb_model=MODEL_PATH)  # âœ… è¿½åŠ å­¦ç¿’
    else:
        print("æ–°è¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™...")
        model = XGBRegressor(
            n_estimators=200,
            max_depth=8,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            objective='reg:squarederror',
            tree_method='hist'  # CPUå‘ã‘é«˜é€Ÿå­¦ç¿’
        )
        model.fit(X_train, y_train)

    # --- ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ ---
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)

    print("\n=== ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ ===")
    print(f"RÂ²ã‚¹ã‚³ã‚¢       : {r2:.4f}")
    print(f"å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {mae:.4f}")
    print(f"MSE (å¹³æ–¹äºŒä¹—èª¤å·®): {mse:.4f}")
    print("=====================\n")

    
    # --- ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤º ---
    importances = model.feature_importances_
    print("\n=== ç‰¹å¾´é‡ã®é‡è¦åº¦ ===")
    for feature_name, importance in zip(features, importances):
        print(f"{feature_name}: {importance:.4f}")
    print("=======================\n")
    # --- ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ ---
    model.save_model(MODEL_PATH)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ãƒ»ä¿å­˜ã—ã¾ã—ãŸ:{MODEL_PATH}")


def predict_comfort_score(sensor_data):
    try:
        model = XGBRegressor()
        model.load_model(MODEL_PATH)
        # DataFrameå‹ã§æ¥ãŸå ´åˆã¯ãã®ã¾ã¾å‹å¤‰æ›
        # --- DataFrameä½œã‚Šç›´ã—ï¼ˆã“ã“ãŒé‡è¦ï¼‰---
        if isinstance(sensor_data, pd.DataFrame):
            sensor_data = sensor_data.iloc[0].to_dict()  # 1è¡Œç›®ã‚’è¾æ›¸ã«å¤‰æ›

        new_data = pd.DataFrame([{
            'avg_temperature': float(sensor_data["avg_temperature"]),
            'avg_humidity': float(sensor_data["avg_humidity"]),
            'avg_light': float(sensor_data["avg_light"]),
            'avg_pressure': float(sensor_data["avg_pressure"]),
            'avg_sound_level': float(sensor_data["avg_sound_level"]),
            'month': int(sensor_data["month"])
        }])

        prediction = model.predict(new_data)
        return float(prediction[0])
    except Exception as e:
        log_error(f"äºˆæ¸¬ã«å¤±æ•—: {str(e)}")
        return None
    

def api_request():
    try:
        tenki_data = requests.get(API_URL).json()
        temp = tenki_data['forecasts'][1]['temperature']['max']['celsius']
        if temp is None:
            log_error("å¤©æ°—APIã‹ã‚‰æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™ or None ã‚’è¿”ã—ã¦å¾Œã§å‡¦ç†ã™ã‚‹
        return temp
    except Exception as e:
        log_error(f"å¤©æ°—APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {str(e)}")
        return 0
    

def count_long_connected_devices(api_token: str,
                                  site_id: str, 
                                  ap_id: str, 
                                  threshold_minutes: int = 5) -> int:
    """
    ç‰¹å®šã®APã«æ¥ç¶šã—ã¦ã„ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã®ã†ã¡ã€uptimeãŒæŒ‡å®šæ™‚é–“ä»¥ä¸Šã®ãƒ‡ãƒã‚¤ã‚¹æ•°ã‚’è¿”ã™é–¢æ•°ã€‚

    Parameters:
        api_token (str): MIST APIãƒˆãƒ¼ã‚¯ãƒ³
        site_id (str): ã‚µã‚¤ãƒˆID
        ap_id (str): APã®ID
        threshold_minutes (int): uptimeã®é–¾å€¤ï¼ˆåˆ†å˜ä½ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30åˆ†ï¼‰

    Returns:
        int: uptimeãŒé–¾å€¤ä»¥ä¸Šã®ãƒ‡ãƒã‚¤ã‚¹æ•°
    """
    # url = f"https://api.ac2.mist.com/api/v1/sites/{site_id}/stats/clients"
    url = f"https://mist-api-wrapper.onrender.com/api/v1/sites/{site_id}/stats/clients"

    headers = {
        "Authorization": f"Token {api_token}",
        "Content-Type": "application/json"
    }

    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"Error {response.status_code}: {response.text}")
        return 0

    clients = response.json()

    # uptimeãŒthreshold_minutesåˆ†ä»¥ä¸Šã®ãƒ‡ãƒã‚¤ã‚¹ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    threshold_seconds = threshold_minutes * 60
    long_connected_devices = [
        c for c in clients
        if c.get("ap_id") == ap_id and c.get("uptime", 0) >= threshold_seconds
    ]

    return len(long_connected_devices)

def parse_format_04(data: bytes):
    if len(data) < 20:
        return None
    return {
        "month":datetime.now().month,
        "timestamp": datetime.now(),
        "temperature": (int.from_bytes(data[1:3], 'little', signed=True) / 100),
        "humidity": int.from_bytes(data[3:5], 'little') / 100,
        "light": int.from_bytes(data[5:7], 'little'),
        "pressure": int.from_bytes(data[9:11], 'little') / 10,
        "sound_level": int.from_bytes(data[11:13], 'little') / 100,
        "battery": data[19] * 0.01
    }

def insert_data_to_sensor_data_for_ml_table(data,device_count,room_id):
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        query = """
            INSERT INTO sensor_data_for_ml
            (timestamp, room_id,temperature, humidity, pressure,light, sound_level, device_count,month, battery)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        cursor.execute(query, (
            data["timestamp"], room_id,data["temperature"], data["humidity"],
            data["pressure"], data["light"],data["sound_level"], device_count,
            data["month"], data["battery"]
        ))
        connection.commit()
        cursor.close()
        connection.close()
    except Exception as e:
        log_error(f"insert_data_to_sensor_data_for_ml_table ã‚¨ãƒ©ãƒ¼: {e}")

    
def generate_advice(data: dict) -> str:
    month = data["month"]
    temp = data["temperature"]
    humidity = data["humidity"]
    pressure = data["pressure"]
    sound = data["sound_level"]
    light = data["light"]

    advice_list = []

    # --- å­£ç¯€åˆ¤å®š ---
    # æ˜¥: 3-5, å¤: 6-8, ç§‹: 9-11, å†¬: 12-2
    if month in [6, 7, 8]:
        season = "summer"
    elif month in [12, 1, 2]:
        season = "winter"
    elif month in [3, 4, 5]:
        season = "spring"
    else:
        season = "autumn"

    # --- æ¸©åº¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ ---
    if season == "summer":
        if temp >= 30:
            advice_list.append("å®¤æ¸©ãŒé«˜ãç†±ä¸­ç—‡ã®ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚å†·æˆ¿ã‚’åˆ©ç”¨ã—ã¾ã—ã‚‡ã†ã€‚")
        elif temp < 26:
            advice_list.append("ã‚„ã‚„æ¶¼ã—ã‚ã®å¿«é©ãªå®¤æ¸©ã§ã™ã€‚")

    elif season == "winter":
        if temp < 18:
            advice_list.append("å®¤æ¸©ãŒä½ãå¯’ãæ„Ÿã˜ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æš–æˆ¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        elif temp >= 26:
            advice_list.append("å®¤æ¸©ãŒã‚„ã‚„é«˜ã‚ã§ã™ã€‚æš–æˆ¿ã®èª¿æ•´ã‚’æ¤œè¨ã—ã¾ã—ã‚‡ã†ã€‚")

    elif season == "spring":
        if temp < 20:
            advice_list.append("å°‘ã—è‚Œå¯’ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")

    elif season == "autumn":
        if temp > 27:
            advice_list.append("æš‘ãæ„Ÿã˜ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å†·æˆ¿ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")

    # --- éŸ³ï¼ˆé¨’éŸ³ï¼‰ã‚¢ãƒ‰ãƒã‚¤ã‚¹ ---
    if sound > 70:
        advice_list.append("é¨’éŸ³ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€é›†ä¸­ã—ã«ãã„ç’°å¢ƒã§ã™ã€‚é™ã‹ãªå ´æ‰€ã¸ã®ç§»å‹•ã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€‚")

    # --- æ°—åœ§ã‚¢ãƒ‰ãƒã‚¤ã‚¹ ---
    if pressure < 1000:
        advice_list.append("æ°—åœ§ãŒä½ãã€é ­ç—›ã‚„ã ã‚‹ã•ã‚’æ„Ÿã˜ã‚‹äººãŒã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")

    # --- æ¹¿åº¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ ---
    if season == "summer" and humidity > 70:
        advice_list.append("æ¹¿åº¦ãŒé«˜ãè’¸ã—æš‘ãæ„Ÿã˜ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚é™¤æ¹¿å™¨ã‚„å†·æˆ¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")

    if season == "winter" and humidity < 40:
        advice_list.append("æ¹¿åº¦ãŒä½ãä¹¾ç‡¥ã—ã¦ã„ã¾ã™ã€‚åŠ æ¹¿å™¨ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚")
    
    # --- ç…§åº¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ ---
    if  light > 750:
        advice_list.append("å°‘ã—çœ©ã—ã„ç’°å¢ƒã§ã™ã€‚çª“ã‚’é–‰ã‚ãŸã‚Šã€ãƒ©ã‚¤ãƒˆã‚’å¼±ãã—ãŸæ–¹ãŒã„ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
    elif light < 500:
        advice_list.append("æš—ãã¦è¦‹ãˆã«ãã„ç’°å¢ƒã§ã™ã€‚éƒ¨å±‹ã®ç…§æ˜ã‚’ã¤ã‘ãŸã‚Šã€çª“ã‚’é–‹ã‘ã¾ã—ã‚‡ã†ã€‚")



    # --- æœ€çµ‚å‡ºåŠ› ---
    if advice_list:
        return " ".join(advice_list)
    else:
        return "ç‰¹ã«ãªã—"


def insert_data_to_sensor_data_table(data,room_id):
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        query = """
            INSERT INTO sensor_data
            (timestamp, room_id,temperature, humidity, pressure,light, sound_level, month, battery)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        cursor.execute(query, (
            data["timestamp"], room_id,data["temperature"], data["humidity"],
            data["pressure"], data["light"],data["sound_level"],
            data["month"], data["battery"]
        ))
        connection.commit()
        cursor.close()
        connection.close()
    except Exception as e:
        log_error(f"insert_data_to_sensor_data_table ã‚¨ãƒ©ãƒ¼: {e}")

    
def insert_comfort_data(data, comfort_score,room_id,processed_sensor_data_id):
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        query = """
            INSERT INTO comfort_data (timestamp, room_id, score, advice,processed_sensor_data_id)
            VALUES (%s, %s, %s, %s,%s)
        """
        print(f"å¿«é©æŒ‡æ•°:{comfort_score}")
        # advice = "å¿«é©ã§ã™" if comfort_score > 0.7 else "å°‘ã—èª¿æ•´ãŒå¿…è¦ã§ã™"
        advice = generate_advice(data)
        cursor.execute(query, (
            data["timestamp"], room_id, comfort_score, advice,processed_sensor_data_id
        ))
        connection.commit()
        cursor.close()
        connection.close()
    except Exception as e:
        log_error(f"insert_comfort_data ã‚¨ãƒ©ãƒ¼: {e}")


def background_training():
    """ä¸€å®šæ™‚é–“ã”ã¨ã«å†å­¦ç¿’"""
    while True:
        print("\n=== è‡ªå‹•ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é–‹å§‹ ===")
        cleanup_old_sensor_data()
        train_and_save_model()
        gc.collect()
        print("=== ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº† ===\n")
        time.sleep(UPDATE_INTERVAL)





def process_sensor_data(omron_address, room_id):
    try:
        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)

        # æœ€æ–°3ä»¶ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
        cursor.execute("SELECT * FROM sensor_data WHERE room_id = %s ORDER BY timestamp DESC LIMIT 3;", (room_id,))
        all_rows = cursor.fetchall()
        cursor.close()

        # ãƒ‡ãƒ¼ã‚¿ãŒ3ä»¶æœªæº€ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
        if len(all_rows) < 3:
            log_error(f"{omron_address} ã®é‹ç”¨ç”¨ãƒ‡ãƒ¼ã‚¿ãŒ3ä»¶æœªæº€ã®ãŸã‚ã€å¹³å‡è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚({len(all_rows)}ä»¶)")
            if 'conn' in locals() and conn:
                conn.close()
            return

        # å¹³å‡å€¤ã‚’ç®—å‡º
        avg_data = {
            'timestamp': all_rows[0]['timestamp'],  # æœ€æ–°ã®æ™‚åˆ»ã‚’ä½¿ç”¨
            'avg_temperature': round(sum(d['temperature'] for d in all_rows) / 3,1),
            'avg_humidity': round(sum(d['humidity'] for d in all_rows) / 3,1),
            'avg_light': round(sum(d['light'] for d in all_rows) / 3,1),
            'avg_pressure': round(sum(d['pressure'] for d in all_rows) / 3,1),
            'avg_sound_level': round(sum(d['sound_level'] for d in all_rows) / 3,1),
            'battery': all_rows[0]['battery'],
            'month': all_rows[0]['month'],
        }

        avg_cursor = conn.cursor()
        avg_cursor.execute("""
            INSERT INTO processed_sensor_data (
                timestamp, room_id, avg_temperature, avg_humidity, avg_pressure, avg_light,
                avg_sound_level, month, battery
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            avg_data['timestamp'], room_id,
            avg_data['avg_temperature'], avg_data['avg_humidity'],
            avg_data['avg_pressure'], avg_data['avg_light'],
            avg_data['avg_sound_level'],
            avg_data['month'], avg_data['battery']
        ))

        conn.commit()
        avg_cursor.close()
        conn.close()

        print(f"âœ… {omron_address} ã® {avg_data['timestamp']} åŒºé–“å¹³å‡ã‚’è¨ˆç®—ãƒ»ä¿å­˜ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        # --- ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ› ---
        log_error(f"process_sensor_dataä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ({omron_address}): {str(e)}")

        # DBã‚’å®‰å…¨ã«ã‚¯ãƒ­ãƒ¼ã‚ºï¼ˆã‚‚ã—é–‹ã„ã¦ã„ãŸã‚‰ï¼‰
        try:
            if 'cursor' in locals() and cursor:
                cursor.close()
            if 'avg_cursor' in locals() and avg_cursor:
                avg_cursor.close()
            if 'conn' in locals() and conn:
                conn.close()
        except:
            pass


def process_sensor_data_for_ml(omron_address,room_id):
    try:

        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)
    
        # ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        cursor.execute("SELECT * FROM sensor_data_for_ml ORDER BY timestamp DESC limit 3;")
        all_rows = cursor.fetchall()
        cursor.close()

        # ãƒ‡ãƒ¼ã‚¿ãŒ3ä»¶æœªæº€ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
        if len(all_rows) < 3:
            log_error(f"{omron_address} ã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ãŒ3ä»¶æœªæº€ã®ãŸã‚ã€å¹³å‡è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚({len(all_rows)}ä»¶)")
            if 'conn' in locals() and conn:
                conn.close()
            return
        
         # 3ä»¶æœªæº€ã¯ç„¡è¦–
        avg_device_count=sum(d['device_count'] for d in all_rows) / 3
        # å¹³å‡è¨ˆç®—
        avg_data = {
            'timestamp': all_rows[0]['timestamp'],  # æœ€åˆã®æ™‚åˆ»ã‚’ä½¿ã†
            'avg_temperature': round(sum(d['temperature'] for d in all_rows) / 3,1),
            'avg_humidity': round(sum(d['humidity'] for d in all_rows) / 3,1),
            'avg_light': round(sum(d['light'] for d in all_rows) / 3,1),
            'avg_pressure': round(sum(d['pressure'] for d in all_rows) / 3,1),
            'avg_sound_level': round(sum(d['sound_level'] for d in all_rows) / 3,1),
            'avg_device_count':round(sum(d['device_count'] for d in all_rows) / 3,1),
            'battery': all_rows[0]['battery'],
            'month':all_rows[0]['month'],
            'score_from_avg_device_count':round(min((avg_device_count/2.5)/CAPACITY*100,100),1),
        }
        # INSERT
        avg_cursor = conn.cursor()
        avg_cursor.execute("""
            INSERT INTO processed_sensor_data_for_ml (
                timestamp, room_id,avg_temperature, avg_humidity,   avg_pressure,avg_light,
                avg_sound_level, avg_device_count, month,battery,score_from_avg_device_count
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s ,%s,%s,%s)
        """, (
            avg_data['timestamp'], room_id,avg_data['avg_temperature'], avg_data['avg_humidity'],
            avg_data['avg_pressure'],avg_data['avg_light'],  
            avg_data['avg_sound_level'], avg_data['avg_device_count'],
            avg_data['month'],avg_data['battery'],avg_data['score_from_avg_device_count']
        ))
        conn.commit()
        avg_cursor.close()
        conn.close()
        print(f"sensor_data_for_mlã®{avg_data['timestamp']}åŒºé–“å¹³å‡ã®è¨ˆç®—ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    

    except Exception as e:
        # --- ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ› ---
        log_error(f"process_sensor_data_for_mlä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ({omron_address}): {str(e)}")

        # DBã‚’å®‰å…¨ã«ã‚¯ãƒ­ãƒ¼ã‚ºï¼ˆã‚‚ã—é–‹ã„ã¦ã„ãŸã‚‰ï¼‰
        try:
            if 'cursor' in locals() and cursor:
                cursor.close()
            if 'avg_cursor' in locals() and avg_cursor:
                avg_cursor.close()
            if 'conn' in locals() and conn:
                conn.close()
        except:
            pass   


# ã‚¨ãƒ©ãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒªã‚¹ãƒˆã«è¨˜éŒ²
error_log = []

def log_error(message):
    entry = {
        "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "error": message
    }
    error_log.append(entry)
    print(f"[ERROR] {entry}")
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ä¿å­˜
    if os.path.exists(ERROR_LOG_FILE):
        with open(ERROR_LOG_FILE, "r", encoding="utf-8") as f:
            try:
                logs = json.load(f)
            except json.JSONDecodeError:
                logs = []
    else:
        logs = []

    logs.append(entry)
    with open(ERROR_LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(logs, f, ensure_ascii=False, indent=2)

# BLEã‚¹ã‚­ãƒ£ãƒ³å‡¦ç†
parsed_counts = {}  # â† omron_addressã”ã¨ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’ä¿æŒã™ã‚‹è¾æ›¸

async def periodic_scan(interval=60):
    while True:
        try:
            for omron_address,room_id in zip(OMRON_ADDRESSES, ROOM_IDS):
                print(f"ğŸ“¡{omron_address}ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­..")
                scanner = BleakScanner()
                await scanner.start()
                await asyncio.sleep(20.0)
                await scanner.stop()
                devices_info = scanner.discovered_devices_and_advertisement_data
                

                if omron_address not in devices_info:
                    log_error(f"{omron_address}ã®ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    continue

                
                adv_data = devices_info[omron_address][1]
                raw_data = adv_data.manufacturer_data.get(OMRON_MANUFACTURER_ID)
                
                if not raw_data:
                    log_error(f"{omron_address}ã®Manufacturer data ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    continue

                parsed = parse_format_04(raw_data)
                if not parsed:
                    log_error(f"{omron_address}ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    continue

                # === ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ ===
                print(f"[SUCCESS] ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ({omron_address}): {parsed}")

                # --- ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ã¨å‡¦ç† ---
                if omron_address == OMRON_ADDRESS_FOR_ML:
                    try:
                        api_data= count_long_connected_devices(API_TOKEN, SITE_ID, AP_ID)
                        print(f"5åˆ†ä»¥ä¸Šæ¥ç¶šã—ã¦ã„ã‚‹ãƒ‡ãƒã‚¤ã‚¹æ•°: {api_data}")
                    except Exception as e:
                        print(f"MIST APIã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                        api_data = int(api_request())

                    insert_data_to_sensor_data_for_ml_table(parsed, api_data, room_id)
                else:
                    insert_data_to_sensor_data_table(parsed, room_id)
                    
                # === ã‚«ã‚¦ãƒ³ãƒˆç®¡ç† ===
                parsed_counts[omron_address] = parsed_counts.get(omron_address, 0) + 1

                # 3å›å–å¾—ã”ã¨ã« test() å®Ÿè¡Œ
                if parsed_counts[omron_address] % 3 == 0:
                    print(f"âœ… {omron_address}ã§3å›ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
                    if omron_address==OMRON_ADDRESS_FOR_ML:
                        print("process_sensor_data_for_ml")
                        process_sensor_data_for_ml(omron_address,room_id)
                    else:
                        print("process_sensor_data")
                        process_sensor_data(omron_address,room_id)
                        lateset_processed_sensor_data=get_lateset_processed_sensor_data()
                        print(f"lateset_processed_sensor_data: {lateset_processed_sensor_data}")
                        current_time = datetime.now()
                        if lateset_processed_sensor_data.empty:
                            print(f"{current_time}æ™‚ç‚¹ã§processed_sensor_dataã«ãƒ‡ãƒ¼ã‚¿ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        else:
                            # æœ€æ–°è¡Œã‚’è¾æ›¸å½¢å¼ã§å–å¾—
                            features = [
                                'avg_temperature',
                                'avg_humidity',
                                'avg_light',
                                'avg_pressure',
                                'avg_sound_level',
                                'month'
                            ]
                            latest_row = lateset_processed_sensor_data.iloc[0][features]
                            comfort_score = predict_comfort_score(latest_row)
                        # --- ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã«åˆ†å‰² ---
    
                        if comfort_score is not None:
                            print(f"äºˆæ¸¬å¿«é©æŒ‡æ•°: {comfort_score}")
                            id_value = int(lateset_processed_sensor_data["id"].iloc[0])

                            insert_comfort_data(parsed, comfort_score, room_id, id_value)
                        else:
                            print("äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            log_error(f"ã‚¹ã‚­ãƒ£ãƒ³ä¸­ã«ä¾‹å¤–ç™ºç”Ÿ: {str(e)}")

        await asyncio.sleep(interval)


def cleanup_old_sensor_data():
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        tables = [
            "sensor_data",
            "sensor_data_for_ml",
            "processed_sensor_data",
            "processed_sensor_data_for_ml",
            "comfort_data"
        ]

        for table in tables:
            delete_query = f"""
                DELETE FROM {table}
                WHERE timestamp < NOW() - INTERVAL 1 MONTH;
            """
            cursor.execute(delete_query)
            print(f"ğŸ§¹ {table}: å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ ({cursor.rowcount} ä»¶)")

        conn.commit()
        cursor.close()
        conn.close()
        print("âœ… 1ãƒ¶æœˆä»¥ä¸Šå‰ã®ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å‰Šé™¤å®Œäº†")

    except Exception as e:
        print(f"[ERROR] è‡ªå‹•å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")

def run_ble_loop():
    asyncio.run(periodic_scan())


@app.route('/')
def home():
    connection = get_db_connection()  # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—
    cursor = connection.cursor()  # ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚«ãƒ¼ã‚½ãƒ«ã‚’å–å¾—
    cursor.execute("SELECT id,room_name FROM room_info WHERE room_type = 1;")  # greetingsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰messageåˆ—ã‚’å–å¾—
    rooms = cursor.fetchall()  # å–å¾—ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã™ã¹ã¦ãƒªã‚¹ãƒˆã§å–å¾—
    cursor.close()  # ã‚«ãƒ¼ã‚½ãƒ«ã‚’é–‰ã˜ã‚‹
    connection.close()
    return render_template('select2.html' ,rooms=rooms)




#bleã‚»ãƒ³ã‚µãƒ¼ã®è¨˜éŒ²ã‚’è¦‹ã‚‹
@app.route("/look", methods=["POST"])
def move_display_page():
    room_id = request.form.get("room_id")
    room_name = request.form.get("room_name")
    print(f"å—ã‘å–ã£ãŸ room_id:{room_id} room_name:{room_name}")
    connection = get_db_connection()
    cursor = connection.cursor(dictionary=True)
    cursor.execute(
        "SELECT * FROM comfort_data WHERE room_id = %s ORDER BY timestamp DESC LIMIT 1",
        (room_id,)
    )
    predicted_data = cursor.fetchone()
    print(f"predicted_data:{predicted_data}")
    processed_sensor_data_id=predicted_data["processed_sensor_data_id"]
    cursor.execute(
        "SELECT * FROM processed_sensor_data WHERE id = %s",
        (processed_sensor_data_id,)
    )
    latest_data = cursor.fetchone()
    cursor.execute(
        "SELECT * FROM processed_sensor_data WHERE room_id = %s ORDER BY timestamp DESC LIMIT 10",
        (room_id,)
    )    
    datas_for_log = cursor.fetchall()
     # ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    cursor.execute(
        "SELECT COUNT(*) AS cnt FROM processed_sensor_data WHERE room_id = %s",
        (room_id,)
    )
    data_count = cursor.fetchone()["cnt"]
    cursor.close()
    connection.close()
    return render_template('display2.html', 
                           room_id=room_id,
                           room_name=room_name,
                           predicted_data=predicted_data,
                           latest_data=latest_data,
                           datas_for_log=datas_for_log,
                           data_count=data_count)



@app.route("/api/latest/<int:room_id>")
def get_latest_data(room_id):
    connection = get_db_connection()
    cursor = connection.cursor(dictionary=True)
    # æœ€æ–°ã®å¿«é©æŒ‡æ•°
    cursor.execute(
        "SELECT * FROM comfort_data WHERE room_id = %s ORDER BY timestamp DESC LIMIT 1",
        (room_id,)
    )
    
    predicted_data = cursor.fetchone()
    processed_sensor_data_id=predicted_data["processed_sensor_data_id"]
    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿
    cursor.execute(
        "SELECT * FROM processed_sensor_data WHERE id = %s",
        (processed_sensor_data_id,)
    )
    latest_data = cursor.fetchone()
    # ãƒ‡ãƒ¼ã‚¿ä»¶æ•°
    cursor.execute(
        "SELECT COUNT(*) AS cnt FROM processed_sensor_data WHERE room_id = %s",
        (room_id,)
    )
    data_count = cursor.fetchone()["cnt"]
    # æœ€æ–°10ä»¶ã®ãƒ­ã‚°
    cursor.execute(
        "SELECT * FROM processed_sensor_data WHERE room_id = %s ORDER BY timestamp DESC LIMIT 10",
        (room_id,)
    )
    datas_for_log = cursor.fetchall()
    cursor.close()
    connection.close()

    return jsonify({
        "latest_data": latest_data,
        "predicted_data": predicted_data,
        "data_count": data_count,
        "datas_for_log":datas_for_log
    })

@app.route('/errors')
def show_errors():
    # æœ€æ–°ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¡¨ç¤º
    if os.path.exists(ERROR_LOG_FILE):
        with open(ERROR_LOG_FILE, "r", encoding="utf-8") as f:
            try:
                logs = json.load(f)
            except json.JSONDecodeError:
                logs = [{"timestamp": "N/A", "error": "JSON decode error"}]
    else:
        logs = [{"timestamp": "N/A", "error": "ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"}]
    return render_template('errors.html', logs=logs)

if __name__ == '__main__':
    thread = threading.Thread(target=background_training, daemon=True)
    thread.start()
    ble_thread = Thread(target=run_ble_loop)
    ble_thread.daemon = True
    ble_thread.start()
    app.run(host='0.0.0.0', port=5001)